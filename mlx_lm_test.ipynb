{
 "cells": [
  {
   "cell_type": "code",
   "id": "initial_id",
   "metadata": {
    "collapsed": true,
    "ExecuteTime": {
     "end_time": "2025-08-08T14:05:29.547556Z",
     "start_time": "2025-08-08T14:05:27.459536Z"
    }
   },
   "source": "!pip install \"mlx[cuda]\"",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting mlx[cuda]\r\n",
      "  Downloading mlx-0.28.0-cp312-cp312-macosx_14_0_arm64.whl.metadata (5.7 kB)\r\n",
      "Collecting mlx-metal==0.28.0 (from mlx[cuda])\r\n",
      "  Using cached mlx_metal-0.28.0-py3-none-macosx_14_0_arm64.whl.metadata (5.1 kB)\r\n",
      "Downloading mlx-0.28.0-cp312-cp312-macosx_14_0_arm64.whl (540 kB)\r\n",
      "\u001B[2K   \u001B[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001B[0m \u001B[32m540.1/540.1 kB\u001B[0m \u001B[31m9.4 MB/s\u001B[0m eta \u001B[36m0:00:00\u001B[0m\r\n",
      "\u001B[?25hUsing cached mlx_metal-0.28.0-py3-none-macosx_14_0_arm64.whl (33.2 MB)\r\n",
      "Installing collected packages: mlx-metal, mlx\r\n",
      "\u001B[2K   \u001B[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001B[0m \u001B[32m2/2\u001B[0m [mlx]\u001B[32m1/2\u001B[0m [mlx]\r\n",
      "\u001B[1A\u001B[2KSuccessfully installed mlx-0.28.0 mlx-metal-0.28.0\r\n",
      "\r\n",
      "\u001B[1m[\u001B[0m\u001B[34;49mnotice\u001B[0m\u001B[1;39;49m]\u001B[0m\u001B[39;49m A new release of pip is available: \u001B[0m\u001B[31;49m25.1.1\u001B[0m\u001B[39;49m -> \u001B[0m\u001B[32;49m25.2\u001B[0m\r\n",
      "\u001B[1m[\u001B[0m\u001B[34;49mnotice\u001B[0m\u001B[1;39;49m]\u001B[0m\u001B[39;49m To update, run: \u001B[0m\u001B[32;49mpip install --upgrade pip\u001B[0m\r\n"
     ]
    }
   ],
   "execution_count": 1
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-08-08T14:05:43.362868Z",
     "start_time": "2025-08-08T14:05:37.873454Z"
    }
   },
   "cell_type": "code",
   "source": "!pip install mlx-lm",
   "id": "cefba48a14a8aaf3",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting mlx-lm\r\n",
      "  Using cached mlx_lm-0.26.3-py3-none-any.whl.metadata (10 kB)\r\n",
      "Requirement already satisfied: mlx>=0.26.0 in /Users/sameerchandra/PycharmProjects/multi-modal-researcher/.venv/lib/python3.12/site-packages (from mlx-lm) (0.28.0)\r\n",
      "Requirement already satisfied: numpy in /Users/sameerchandra/PycharmProjects/multi-modal-researcher/.venv/lib/python3.12/site-packages (from mlx-lm) (2.3.1)\r\n",
      "Collecting transformers>=4.39.3 (from mlx-lm)\r\n",
      "  Using cached transformers-4.55.0-py3-none-any.whl.metadata (39 kB)\r\n",
      "Collecting protobuf (from mlx-lm)\r\n",
      "  Using cached protobuf-6.31.1-cp39-abi3-macosx_10_9_universal2.whl.metadata (593 bytes)\r\n",
      "Requirement already satisfied: pyyaml in /Users/sameerchandra/PycharmProjects/multi-modal-researcher/.venv/lib/python3.12/site-packages (from mlx-lm) (6.0.2)\r\n",
      "Requirement already satisfied: jinja2 in /Users/sameerchandra/PycharmProjects/multi-modal-researcher/.venv/lib/python3.12/site-packages (from mlx-lm) (3.1.6)\r\n",
      "Requirement already satisfied: mlx-metal==0.28.0 in /Users/sameerchandra/PycharmProjects/multi-modal-researcher/.venv/lib/python3.12/site-packages (from mlx>=0.26.0->mlx-lm) (0.28.0)\r\n",
      "Collecting filelock (from transformers>=4.39.3->mlx-lm)\r\n",
      "  Using cached filelock-3.18.0-py3-none-any.whl.metadata (2.9 kB)\r\n",
      "Collecting huggingface-hub<1.0,>=0.34.0 (from transformers>=4.39.3->mlx-lm)\r\n",
      "  Using cached huggingface_hub-0.34.4-py3-none-any.whl.metadata (14 kB)\r\n",
      "Requirement already satisfied: packaging>=20.0 in /Users/sameerchandra/PycharmProjects/multi-modal-researcher/.venv/lib/python3.12/site-packages (from transformers>=4.39.3->mlx-lm) (25.0)\r\n",
      "Collecting regex!=2019.12.17 (from transformers>=4.39.3->mlx-lm)\r\n",
      "  Using cached regex-2025.7.34-cp312-cp312-macosx_11_0_arm64.whl.metadata (40 kB)\r\n",
      "Requirement already satisfied: requests in /Users/sameerchandra/PycharmProjects/multi-modal-researcher/.venv/lib/python3.12/site-packages (from transformers>=4.39.3->mlx-lm) (2.32.4)\r\n",
      "Collecting tokenizers<0.22,>=0.21 (from transformers>=4.39.3->mlx-lm)\r\n",
      "  Using cached tokenizers-0.21.4-cp39-abi3-macosx_11_0_arm64.whl.metadata (6.7 kB)\r\n",
      "Collecting safetensors>=0.4.3 (from transformers>=4.39.3->mlx-lm)\r\n",
      "  Downloading safetensors-0.6.2-cp38-abi3-macosx_11_0_arm64.whl.metadata (4.1 kB)\r\n",
      "Collecting tqdm>=4.27 (from transformers>=4.39.3->mlx-lm)\r\n",
      "  Using cached tqdm-4.67.1-py3-none-any.whl.metadata (57 kB)\r\n",
      "Collecting fsspec>=2023.5.0 (from huggingface-hub<1.0,>=0.34.0->transformers>=4.39.3->mlx-lm)\r\n",
      "  Using cached fsspec-2025.7.0-py3-none-any.whl.metadata (12 kB)\r\n",
      "Requirement already satisfied: typing-extensions>=3.7.4.3 in /Users/sameerchandra/PycharmProjects/multi-modal-researcher/.venv/lib/python3.12/site-packages (from huggingface-hub<1.0,>=0.34.0->transformers>=4.39.3->mlx-lm) (4.14.1)\r\n",
      "Collecting hf-xet<2.0.0,>=1.1.3 (from huggingface-hub<1.0,>=0.34.0->transformers>=4.39.3->mlx-lm)\r\n",
      "  Using cached hf_xet-1.1.7-cp37-abi3-macosx_11_0_arm64.whl.metadata (703 bytes)\r\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in /Users/sameerchandra/PycharmProjects/multi-modal-researcher/.venv/lib/python3.12/site-packages (from jinja2->mlx-lm) (3.0.2)\r\n",
      "Requirement already satisfied: charset_normalizer<4,>=2 in /Users/sameerchandra/PycharmProjects/multi-modal-researcher/.venv/lib/python3.12/site-packages (from requests->transformers>=4.39.3->mlx-lm) (3.4.2)\r\n",
      "Requirement already satisfied: idna<4,>=2.5 in /Users/sameerchandra/PycharmProjects/multi-modal-researcher/.venv/lib/python3.12/site-packages (from requests->transformers>=4.39.3->mlx-lm) (3.10)\r\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /Users/sameerchandra/PycharmProjects/multi-modal-researcher/.venv/lib/python3.12/site-packages (from requests->transformers>=4.39.3->mlx-lm) (2.5.0)\r\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /Users/sameerchandra/PycharmProjects/multi-modal-researcher/.venv/lib/python3.12/site-packages (from requests->transformers>=4.39.3->mlx-lm) (2025.7.9)\r\n",
      "Using cached mlx_lm-0.26.3-py3-none-any.whl (235 kB)\r\n",
      "Using cached transformers-4.55.0-py3-none-any.whl (11.3 MB)\r\n",
      "Using cached huggingface_hub-0.34.4-py3-none-any.whl (561 kB)\r\n",
      "Using cached hf_xet-1.1.7-cp37-abi3-macosx_11_0_arm64.whl (2.6 MB)\r\n",
      "Using cached tokenizers-0.21.4-cp39-abi3-macosx_11_0_arm64.whl (2.7 MB)\r\n",
      "Using cached fsspec-2025.7.0-py3-none-any.whl (199 kB)\r\n",
      "Using cached regex-2025.7.34-cp312-cp312-macosx_11_0_arm64.whl (286 kB)\r\n",
      "Downloading safetensors-0.6.2-cp38-abi3-macosx_11_0_arm64.whl (432 kB)\r\n",
      "Using cached tqdm-4.67.1-py3-none-any.whl (78 kB)\r\n",
      "Using cached filelock-3.18.0-py3-none-any.whl (16 kB)\r\n",
      "Using cached protobuf-6.31.1-cp39-abi3-macosx_10_9_universal2.whl (425 kB)\r\n",
      "Installing collected packages: tqdm, safetensors, regex, protobuf, hf-xet, fsspec, filelock, huggingface-hub, tokenizers, transformers, mlx-lm\r\n",
      "\u001B[2K   \u001B[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001B[0m \u001B[32m11/11\u001B[0m [mlx-lm]10/11\u001B[0m [mlx-lm]rmers]ub]\r\n",
      "\u001B[1A\u001B[2KSuccessfully installed filelock-3.18.0 fsspec-2025.7.0 hf-xet-1.1.7 huggingface-hub-0.34.4 mlx-lm-0.26.3 protobuf-6.31.1 regex-2025.7.34 safetensors-0.6.2 tokenizers-0.21.4 tqdm-4.67.1 transformers-4.55.0\r\n",
      "\r\n",
      "\u001B[1m[\u001B[0m\u001B[34;49mnotice\u001B[0m\u001B[1;39;49m]\u001B[0m\u001B[39;49m A new release of pip is available: \u001B[0m\u001B[31;49m25.1.1\u001B[0m\u001B[39;49m -> \u001B[0m\u001B[32;49m25.2\u001B[0m\r\n",
      "\u001B[1m[\u001B[0m\u001B[34;49mnotice\u001B[0m\u001B[1;39;49m]\u001B[0m\u001B[39;49m To update, run: \u001B[0m\u001B[32;49mpip install --upgrade pip\u001B[0m\r\n"
     ]
    }
   ],
   "execution_count": 2
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-08-08T14:06:27.009018Z",
     "start_time": "2025-08-08T14:06:26.039720Z"
    }
   },
   "cell_type": "code",
   "source": "!pip install sentencepiece",
   "id": "dc2cdf632668acf5",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting sentencepiece\r\n",
      "  Downloading sentencepiece-0.2.0-cp312-cp312-macosx_11_0_arm64.whl.metadata (7.7 kB)\r\n",
      "Downloading sentencepiece-0.2.0-cp312-cp312-macosx_11_0_arm64.whl (1.2 MB)\r\n",
      "\u001B[2K   \u001B[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001B[0m \u001B[32m1.2/1.2 MB\u001B[0m \u001B[31m10.2 MB/s\u001B[0m eta \u001B[36m0:00:00\u001B[0m\r\n",
      "\u001B[?25hInstalling collected packages: sentencepiece\r\n",
      "Successfully installed sentencepiece-0.2.0\r\n",
      "\r\n",
      "\u001B[1m[\u001B[0m\u001B[34;49mnotice\u001B[0m\u001B[1;39;49m]\u001B[0m\u001B[39;49m A new release of pip is available: \u001B[0m\u001B[31;49m25.1.1\u001B[0m\u001B[39;49m -> \u001B[0m\u001B[32;49m25.2\u001B[0m\r\n",
      "\u001B[1m[\u001B[0m\u001B[34;49mnotice\u001B[0m\u001B[1;39;49m]\u001B[0m\u001B[39;49m To update, run: \u001B[0m\u001B[32;49mpip install --upgrade pip\u001B[0m\r\n"
     ]
    }
   ],
   "execution_count": 4
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-08-09T03:09:29.243148Z",
     "start_time": "2025-08-09T03:09:16.350888Z"
    }
   },
   "cell_type": "code",
   "source": "!python3 -m mlx_lm generate --model mlx-community/Mistral-7B-Instruct-v0.3-4bit --prompt \"how far is earth from dying?\"",
   "id": "aa1760f5e95e99bd",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fetching 7 files: 100%|████████████████████████| 7/7 [00:00<00:00, 63550.06it/s]\r\n",
      "==========\r\n",
      "The question seems to imply that Earth is a living entity that can die, which is not accurate. Earth is a planet, not a living organism. However, if you're asking about the potential for human extinction or the end of Earth's habitability, that's a complex question with many variables.\r\n",
      "\r\n",
      "Currently, there are several long-term threats to Earth's habitability, such as climate change, loss of biodiversity, and resource depletion\r\n",
      "==========\r\n",
      "Prompt: 12 tokens, 9.570 tokens-per-sec\r\n",
      "Generation: 100 tokens, 21.262 tokens-per-sec\r\n",
      "Peak memory: 4.136 GB\r\n"
     ]
    }
   ],
   "execution_count": 1
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-08-08T14:27:33.703984Z",
     "start_time": "2025-08-08T14:27:17.013559Z"
    }
   },
   "cell_type": "code",
   "source": "!python3 -m mlx_lm chat --model mlx-community/Mistral-7B-Instruct-v0.3-4bit",
   "id": "3c7ed5cd51180d1b",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fetching 7 files: 100%|███████████████████████| 7/7 [00:00<00:00, 118866.91it/s]\r\n",
      "[INFO] Starting chat session with mlx-community/Mistral-7B-Instruct-v0.3-4bit.\r\n",
      "The command list:\r\n",
      "- 'q' to exit\r\n",
      "- 'r' to reset the chat\r\n",
      "- 'h' to display these commands\r\n",
      ">> ^C\r\n",
      "Traceback (most recent call last):\r\n",
      "  File \"<frozen runpy>\", line 198, in _run_module_as_main\r\n",
      "  File \"<frozen runpy>\", line 88, in _run_code\r\n",
      "  File \"/Users/sameerchandra/PycharmProjects/multi-modal-researcher/.venv/lib/python3.12/site-packages/mlx_lm/__main__.py\", line 29, in <module>\r\n",
      "    submodule.main()\r\n",
      "  File \"/Users/sameerchandra/PycharmProjects/multi-modal-researcher/.venv/lib/python3.12/site-packages/mlx_lm/chat.py\", line 110, in main\r\n",
      "    query = input(\">> \")\r\n",
      "            ^^^^^^^^^^^^\r\n",
      "KeyboardInterrupt\r\n"
     ]
    }
   ],
   "execution_count": 10
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
