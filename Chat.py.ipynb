{
 "cells": [
  {
   "cell_type": "code",
   "id": "initial_id",
   "metadata": {
    "collapsed": true,
    "ExecuteTime": {
     "end_time": "2025-08-08T14:28:57.247981Z",
     "start_time": "2025-08-08T14:28:56.430222Z"
    }
   },
   "source": [
    "from mlx_lm import generate, load\n",
    "from mlx_lm.models.cache import load_prompt_cache, make_prompt_cache, save_prompt_cache"
   ],
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/sameerchandra/PycharmProjects/multi-modal-researcher/.venv/lib/python3.12/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "execution_count": 1
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-08-08T14:29:26.100502Z",
     "start_time": "2025-08-08T14:29:23.972659Z"
    }
   },
   "cell_type": "code",
   "source": "model, tokenizer = load(\"mlx-community/Mistral-7B-Instruct-v0.3-4bit\")\n",
   "id": "277a34dea3cdb275",
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Fetching 7 files: 100%|██████████| 7/7 [00:00<00:00, 104484.44it/s]\n"
     ]
    }
   ],
   "execution_count": 2
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-08-08T14:29:50.120711Z",
     "start_time": "2025-08-08T14:29:50.116976Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# Make the initial prompt cache for the model\n",
    "prompt_cache = make_prompt_cache(model)"
   ],
   "id": "d1e42416a1d7ec5c",
   "outputs": [],
   "execution_count": 4
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-08-09T02:27:03.276174Z",
     "start_time": "2025-08-09T02:27:03.253950Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# User turn\n",
    "prompt = \"Write a poem on the Sun in 400 words\"\n",
    "messages = [{\"role\": \"user\", \"content\": prompt}]\n",
    "prompt = tokenizer.apply_chat_template(messages, add_generation_prompt=True)"
   ],
   "id": "41acd85890b08851",
   "outputs": [],
   "execution_count": 57
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-08-09T02:27:25.212231Z",
     "start_time": "2025-08-09T02:27:07.282735Z"
    }
   },
   "cell_type": "code",
   "source": [
    "response = generate(\n",
    "    model,\n",
    "    tokenizer,\n",
    "    max_tokens=1000,\n",
    "    prompt=prompt,\n",
    "    verbose=True,\n",
    "    prompt_cache=prompt_cache,\n",
    ")\n"
   ],
   "id": "8f3b069cfc8d062b",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "==========\n",
      "The Sun, the golden orb of light,\n",
      "A beacon in the sky so bright,\n",
      "Burning with a fiery heart,\n",
      "Illuminating the world with its gentle art.\n",
      "\n",
      "Rising each day, breaking the night,\n",
      "Bathing the world in its gentle light,\n",
      "Giving life to all that it sees,\n",
      "A daily, constant, endless tease.\n",
      "\n",
      "It dances in the sky, a dance so free,\n",
      "A ballet of light and heat,\n",
      "A dance that never ends,\n",
      "A dance that never repeats.\n",
      "\n",
      "It warms the earth, giving life to the land,\n",
      "A dance that never ends,\n",
      "A dance that never wanes,\n",
      "A dance that never bends.\n",
      "\n",
      "The Sun, the source of all life,\n",
      "A constant, eternal light,\n",
      "A dance that never tires,\n",
      "A dance that never quits.\n",
      "\n",
      "It's a dance that we all share,\n",
      "A dance that we all partake,\n",
      "A dance that we all bear,\n",
      "A dance that we all make.\n",
      "\n",
      "The Sun, the dance of life,\n",
      "A dance that we all give,\n",
      "A dance that we all strive,\n",
      "A dance that we all live.\n",
      "\n",
      "The end.\n",
      "==========\n",
      "Prompt: 17 tokens, 7.804 tokens-per-sec\n",
      "Generation: 268 tokens, 17.046 tokens-per-sec\n",
      "Peak memory: 4.874 GB\n"
     ]
    }
   ],
   "execution_count": 58
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
